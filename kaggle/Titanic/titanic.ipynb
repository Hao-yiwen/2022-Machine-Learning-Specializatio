{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 泰坦尼克号测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "X_train = train_data.drop(['PassengerId','Survived', 'Ticket', 'Name', 'Cabin'], axis=1).copy()\n",
    "y_train = train_data['Survived'].copy()\n",
    "\n",
    "\n",
    "# 处理缺失值\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Age'].mean())  # 修改这里\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Fare'].mean())  # 修改这里\n",
    "X_train['Embarked'] = X_train['Embarked'].fillna('S')\n",
    "\n",
    "\n",
    "X_train['Sex'] = (X_train['Sex'] == 'female').astype(np.int64)\n",
    "X_train['Embarked'] = X_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "X_train['FamilySize'] = X_train['SibSp'] + X_train['Parch'] + 1  # 家庭总人数\n",
    "X_train['IsAlone'] = (X_train['FamilySize'] == 1).astype(int)\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "\n",
    "# 删除第一行标题 转化为numpy数组\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.5270 - loss: 0.7167\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6383 - loss: 0.6780\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7026 - loss: 0.6296\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7180 - loss: 0.5977\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7236 - loss: 0.5827\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7574 - loss: 0.5525\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7476 - loss: 0.5389\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7657 - loss: 0.5229\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7669 - loss: 0.5088\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7822 - loss: 0.4792\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7861 - loss: 0.4870\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7988 - loss: 0.4654\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.8143 - loss: 0.4692\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7875 - loss: 0.4808\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.8061 - loss: 0.4694\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8102 - loss: 0.4562\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8075 - loss: 0.4609\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8179 - loss: 0.4299\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8219 - loss: 0.4443\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8229 - loss: 0.4229\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7972 - loss: 0.4597\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8113 - loss: 0.4546\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8252 - loss: 0.4305\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8000 - loss: 0.4568\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7937 - loss: 0.4536\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.8211 - loss: 0.4245\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8071 - loss: 0.4370\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8202 - loss: 0.4312\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8038 - loss: 0.4527\n",
      "Epoch 30/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8201 - loss: 0.4362\n",
      "Epoch 31/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8197 - loss: 0.4345\n",
      "Epoch 32/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.8131 - loss: 0.4441\n",
      "Epoch 33/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8139 - loss: 0.4262\n",
      "Epoch 34/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8352 - loss: 0.4099\n",
      "Epoch 35/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8172 - loss: 0.4200\n",
      "Epoch 36/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8181 - loss: 0.4259\n",
      "Epoch 37/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8308 - loss: 0.4074\n",
      "Epoch 38/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8109 - loss: 0.4394\n",
      "Epoch 39/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.8232 - loss: 0.4247\n",
      "Epoch 40/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8268 - loss: 0.4259\n",
      "Epoch 41/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8379 - loss: 0.4050\n",
      "Epoch 42/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.8343 - loss: 0.4133\n",
      "Epoch 43/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.8076 - loss: 0.4215\n",
      "Epoch 44/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8227 - loss: 0.4156\n",
      "Epoch 45/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8351 - loss: 0.4065\n",
      "Epoch 46/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8159 - loss: 0.4301\n",
      "Epoch 47/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8230 - loss: 0.4223\n",
      "Epoch 48/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8349 - loss: 0.4121\n",
      "Epoch 49/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.8270 - loss: 0.4086\n",
      "Epoch 50/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.8357 - loss: 0.3999\n",
      "Epoch 51/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8121 - loss: 0.4340\n",
      "Epoch 52/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8350 - loss: 0.4112\n",
      "Epoch 53/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.8351 - loss: 0.3932\n",
      "Epoch 54/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.8378 - loss: 0.4073\n",
      "Epoch 55/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8256 - loss: 0.4216\n",
      "Epoch 56/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.8184 - loss: 0.4387\n",
      "Epoch 57/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.8183 - loss: 0.4302\n",
      "Epoch 58/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8266 - loss: 0.4141\n",
      "Epoch 59/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8195 - loss: 0.4299\n",
      "Epoch 60/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8424 - loss: 0.4102\n",
      "Epoch 61/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.8454 - loss: 0.3919\n",
      "Epoch 62/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8416 - loss: 0.3982\n",
      "Epoch 63/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.8539 - loss: 0.3909\n",
      "Epoch 64/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.8384 - loss: 0.4235\n",
      "Epoch 65/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8404 - loss: 0.4186\n",
      "Epoch 66/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8184 - loss: 0.4487\n",
      "Epoch 67/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8276 - loss: 0.4293\n",
      "Epoch 68/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.8525 - loss: 0.3976\n",
      "Epoch 69/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.8316 - loss: 0.4292\n",
      "Epoch 70/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.8653 - loss: 0.3705\n",
      "Epoch 71/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8220 - loss: 0.4339\n",
      "Epoch 72/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8280 - loss: 0.4124\n",
      "Epoch 73/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8471 - loss: 0.4046\n",
      "Epoch 74/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8360 - loss: 0.4152\n",
      "Epoch 75/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8164 - loss: 0.4365\n",
      "Epoch 76/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8302 - loss: 0.4258\n",
      "Epoch 77/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.8176 - loss: 0.4406\n",
      "Epoch 78/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8094 - loss: 0.4347\n",
      "Epoch 79/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8242 - loss: 0.4384\n",
      "Epoch 80/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8252 - loss: 0.4364\n",
      "Epoch 81/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8369 - loss: 0.3976\n",
      "Epoch 82/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.8203 - loss: 0.4299\n",
      "Epoch 83/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.8311 - loss: 0.4174\n",
      "Epoch 84/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8542 - loss: 0.4007\n",
      "Epoch 85/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8438 - loss: 0.4065\n",
      "Epoch 86/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.8656 - loss: 0.3703\n",
      "Epoch 87/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8385 - loss: 0.3897\n",
      "Epoch 88/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.8431 - loss: 0.4229\n",
      "Epoch 89/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8496 - loss: 0.4005\n",
      "Epoch 90/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8341 - loss: 0.4125\n",
      "Epoch 91/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8264 - loss: 0.4301\n",
      "Epoch 92/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.4172 \n",
      "Epoch 93/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8435 - loss: 0.4041\n",
      "Epoch 94/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.8384 - loss: 0.4091\n",
      "Epoch 95/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8523 - loss: 0.3916\n",
      "Epoch 96/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8255 - loss: 0.4305\n",
      "Epoch 97/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8207 - loss: 0.4362\n",
      "Epoch 98/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8492 - loss: 0.4123\n",
      "Epoch 99/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8135 - loss: 0.4466\n",
      "Epoch 100/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.8563 - loss: 0.4010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16dbed1e0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# 创建模型\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.001))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1).copy()\n",
    "\n",
    "\n",
    "# 处理缺失值\n",
    "X_test['Age']= X_test['Age'].fillna(X_test['Age'].mean())\n",
    "X_test['Fare']=X_test['Fare'].fillna(X_test['Fare'].mean())\n",
    "\n",
    "X_test['Sex'] = (X_test['Sex'] == 'female').astype(np.int64)\n",
    "\n",
    "X_test['Embarked'] = X_test['Embarked'].fillna('S')\n",
    "\n",
    "\n",
    "X_test['Embarked'] = X_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "X_test['FamilySize'] = X_test['SibSp'] + X_test['Parch'] + 1  # 家庭总人数\n",
    "X_test['IsAlone'] = (X_test['FamilySize'] == 1).astype(int)\n",
    "\n",
    "\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "# 删除第一行标题 转化为numpy数组\n",
    "X_test = X_test.values\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "# 数据归一化\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "(418, 1)\n",
      "[[0.07419337]\n",
      " [0.27709073]\n",
      " [0.07300826]\n",
      " [0.10960562]\n",
      " [0.39812934]\n",
      " [0.21569872]\n",
      " [0.6798916 ]\n",
      " [0.22246084]\n",
      " [0.667851  ]\n",
      " [0.07856612]\n",
      " [0.10008961]\n",
      " [0.24220821]\n",
      " [0.9748334 ]\n",
      " [0.05995985]\n",
      " [0.97744405]\n",
      " [0.91603684]\n",
      " [0.16606289]\n",
      " [0.20743504]\n",
      " [0.37323228]\n",
      " [0.5546287 ]\n",
      " [0.34452677]\n",
      " [0.6390212 ]\n",
      " [0.95590466]\n",
      " [0.724068  ]\n",
      " [0.89846283]\n",
      " [0.02569442]\n",
      " [0.98199636]\n",
      " [0.17987685]\n",
      " [0.26932356]\n",
      " [0.04228794]\n",
      " [0.07590764]\n",
      " [0.12682344]\n",
      " [0.24591601]\n",
      " [0.25369734]\n",
      " [0.43687356]\n",
      " [0.26001284]\n",
      " [0.4518618 ]\n",
      " [0.50545955]\n",
      " [0.11624294]\n",
      " [0.16338655]\n",
      " [0.07439715]\n",
      " [0.31716514]\n",
      " [0.07327522]\n",
      " [0.82638305]\n",
      " [0.9770206 ]\n",
      " [0.11438172]\n",
      " [0.3116453 ]\n",
      " [0.10505635]\n",
      " [0.9768962 ]\n",
      " [0.338938  ]\n",
      " [0.3906094 ]\n",
      " [0.1966656 ]\n",
      " [0.7746065 ]\n",
      " [0.9095945 ]\n",
      " [0.1607033 ]\n",
      " [0.0708307 ]\n",
      " [0.08867235]\n",
      " [0.1140594 ]\n",
      " [0.06561546]\n",
      " [0.98503894]\n",
      " [0.16932236]\n",
      " [0.12780479]\n",
      " [0.15588458]\n",
      " [0.7818325 ]\n",
      " [0.28967172]\n",
      " [0.8359411 ]\n",
      " [0.8232086 ]\n",
      " [0.2545987 ]\n",
      " [0.32636338]\n",
      " [0.86390233]\n",
      " [0.7587326 ]\n",
      " [0.1264052 ]\n",
      " [0.453384  ]\n",
      " [0.34932068]\n",
      " [0.98378706]\n",
      " [0.47005185]\n",
      " [0.10025062]\n",
      " [0.9786543 ]\n",
      " [0.1335733 ]\n",
      " [0.7587326 ]\n",
      " [0.51513714]\n",
      " [0.46933842]\n",
      " [0.22946514]\n",
      " [0.10008961]\n",
      " [0.23912457]\n",
      " [0.08201622]\n",
      " [0.72112757]\n",
      " [0.53001624]\n",
      " [0.6760792 ]\n",
      " [0.75792676]\n",
      " [0.4143555 ]\n",
      " [0.09996362]\n",
      " [0.96131533]\n",
      " [0.10025062]\n",
      " [0.4097836 ]\n",
      " [0.1142302 ]\n",
      " [0.9794482 ]\n",
      " [0.10341036]\n",
      " [0.51265293]\n",
      " [0.09350303]\n",
      " [0.9859883 ]\n",
      " [0.20662595]\n",
      " [0.10505635]\n",
      " [0.11137527]\n",
      " [0.5971159 ]\n",
      " [0.12319908]\n",
      " [0.25930032]\n",
      " [0.10505635]\n",
      " [0.10094497]\n",
      " [0.1939485 ]\n",
      " [0.12254494]\n",
      " [0.67609787]\n",
      " [0.97183716]\n",
      " [0.81814426]\n",
      " [0.9875942 ]\n",
      " [0.26788446]\n",
      " [0.0925202 ]\n",
      " [0.7571786 ]\n",
      " [0.38022095]\n",
      " [0.8701571 ]\n",
      " [0.8612147 ]\n",
      " [0.10494559]\n",
      " [0.9868204 ]\n",
      " [0.10532352]\n",
      " [0.10505635]\n",
      " [0.66607434]\n",
      " [0.1231017 ]\n",
      " [0.46373865]\n",
      " [0.10385848]\n",
      " [0.11742855]\n",
      " [0.09592839]\n",
      " [0.3180888 ]\n",
      " [0.41966912]\n",
      " [0.08045664]\n",
      " [0.06705847]\n",
      " [0.11719371]\n",
      " [0.12488686]\n",
      " [0.14721932]\n",
      " [0.48737484]\n",
      " [0.04462118]\n",
      " [0.07273912]\n",
      " [0.9731284 ]\n",
      " [0.13937044]\n",
      " [0.15941863]\n",
      " [0.2605144 ]\n",
      " [0.01921349]\n",
      " [0.34796503]\n",
      " [0.12341995]\n",
      " [0.31716514]\n",
      " [0.16320275]\n",
      " [0.97896516]\n",
      " [0.09322261]\n",
      " [0.03988972]\n",
      " [0.33573765]\n",
      " [0.02895563]\n",
      " [0.1168296 ]\n",
      " [0.97269887]\n",
      " [0.48705032]\n",
      " [0.2605144 ]\n",
      " [0.5460872 ]\n",
      " [0.6760686 ]\n",
      " [0.49402267]\n",
      " [0.831728  ]\n",
      " [0.09915882]\n",
      " [0.10580757]\n",
      " [0.35069272]\n",
      " [0.3500061 ]\n",
      " [0.10229671]\n",
      " [0.9750689 ]\n",
      " [0.49742118]\n",
      " [0.09972937]\n",
      " [0.12015963]\n",
      " [0.13597089]\n",
      " [0.09290094]\n",
      " [0.0447356 ]\n",
      " [0.9280918 ]\n",
      " [0.8625078 ]\n",
      " [0.34203297]\n",
      " [0.7201407 ]\n",
      " [0.9560312 ]\n",
      " [0.1335733 ]\n",
      " [0.26118603]\n",
      " [0.9720492 ]\n",
      " [0.10505635]\n",
      " [0.96071535]\n",
      " [0.11042234]\n",
      " [0.8765699 ]\n",
      " [0.11874419]\n",
      " [0.01135644]\n",
      " [0.10778885]\n",
      " [0.1440682 ]\n",
      " [0.31651223]\n",
      " [0.35554513]\n",
      " [0.07515937]\n",
      " [0.8027818 ]\n",
      " [0.09331094]\n",
      " [0.86826134]\n",
      " [0.5295618 ]\n",
      " [0.15437676]\n",
      " [0.4519978 ]\n",
      " [0.6810089 ]\n",
      " [0.7871514 ]\n",
      " [0.46433866]\n",
      " [0.9086826 ]\n",
      " [0.14713484]\n",
      " [0.3270723 ]\n",
      " [0.6085258 ]\n",
      " [0.15072002]\n",
      " [0.9733574 ]\n",
      " [0.11434746]\n",
      " [0.11148839]\n",
      " [0.09921056]\n",
      " [0.30977806]\n",
      " [0.8213046 ]\n",
      " [0.0669309 ]\n",
      " [0.27771708]\n",
      " [0.67616177]\n",
      " [0.30753526]\n",
      " [0.969986  ]\n",
      " [0.10025062]\n",
      " [0.87987477]\n",
      " [0.1265742 ]\n",
      " [0.8312255 ]\n",
      " [0.12629573]\n",
      " [0.9656852 ]\n",
      " [0.5126076 ]\n",
      " [0.12008059]\n",
      " [0.6760792 ]\n",
      " [0.08035124]\n",
      " [0.11604301]\n",
      " [0.32690108]\n",
      " [0.96390325]\n",
      " [0.16344295]\n",
      " [0.10508806]\n",
      " [0.37306815]\n",
      " [0.13358219]\n",
      " [0.33792496]\n",
      " [0.2274724 ]\n",
      " [0.8757942 ]\n",
      " [0.98368025]\n",
      " [0.966076  ]\n",
      " [0.78955954]\n",
      " [0.2789038 ]\n",
      " [0.10008093]\n",
      " [0.08213378]\n",
      " [0.3370943 ]\n",
      " [0.84377134]\n",
      " [0.10563137]\n",
      " [0.8701571 ]\n",
      " [0.4039511 ]\n",
      " [0.9492414 ]\n",
      " [0.1336382 ]\n",
      " [0.4365495 ]\n",
      " [0.11896796]\n",
      " [0.09615875]\n",
      " [0.09972937]\n",
      " [0.10505635]\n",
      " [0.10619998]\n",
      " [0.83663046]\n",
      " [0.12627293]\n",
      " [0.04934614]\n",
      " [0.12635964]\n",
      " [0.85710675]\n",
      " [0.76020414]\n",
      " [0.16059642]\n",
      " [0.10008961]\n",
      " [0.2784811 ]\n",
      " [0.09972937]\n",
      " [0.4518618 ]\n",
      " [0.16972417]\n",
      " [0.39178383]\n",
      " [0.10505635]\n",
      " [0.9829071 ]\n",
      " [0.5410981 ]\n",
      " [0.09289892]\n",
      " [0.8744384 ]\n",
      " [0.13680154]\n",
      " [0.11210956]\n",
      " [0.16976489]\n",
      " [0.1612061 ]\n",
      " [0.48838976]\n",
      " [0.5814788 ]\n",
      " [0.6760792 ]\n",
      " [0.67245156]\n",
      " [0.7395937 ]\n",
      " [0.08582415]\n",
      " [0.09941778]\n",
      " [0.4071286 ]\n",
      " [0.09290094]\n",
      " [0.10025062]\n",
      " [0.33286533]\n",
      " [0.67946047]\n",
      " [0.09290094]\n",
      " [0.26652557]\n",
      " [0.08789131]\n",
      " [0.11151382]\n",
      " [0.95099086]\n",
      " [0.04228794]\n",
      " [0.3415337 ]\n",
      " [0.10333434]\n",
      " [0.09565246]\n",
      " [0.16021231]\n",
      " [0.13885199]\n",
      " [0.11816593]\n",
      " [0.6760792 ]\n",
      " [0.97078216]\n",
      " [0.27756894]\n",
      " [0.7790923 ]\n",
      " [0.271161  ]\n",
      " [0.2908142 ]\n",
      " [0.15633208]\n",
      " [0.18873157]\n",
      " [0.09975537]\n",
      " [0.584083  ]\n",
      " [0.98482925]\n",
      " [0.83246046]\n",
      " [0.40546542]\n",
      " [0.18621166]\n",
      " [0.10869516]\n",
      " [0.14704052]\n",
      " [0.11137527]\n",
      " [0.1404311 ]\n",
      " [0.14721932]\n",
      " [0.30340672]\n",
      " [0.97814107]\n",
      " [0.11917076]\n",
      " [0.8236075 ]\n",
      " [0.39900908]\n",
      " [0.1857332 ]\n",
      " [0.17222458]\n",
      " [0.7867524 ]\n",
      " [0.30540016]\n",
      " [0.09289892]\n",
      " [0.5569458 ]\n",
      " [0.10874184]\n",
      " [0.31790403]\n",
      " [0.12716053]\n",
      " [0.10770401]\n",
      " [0.18034883]\n",
      " [0.09290094]\n",
      " [0.19848843]\n",
      " [0.09545644]\n",
      " [0.06154163]\n",
      " [0.9755756 ]\n",
      " [0.08194759]\n",
      " [0.54632795]\n",
      " [0.14721932]\n",
      " [0.5662546 ]\n",
      " [0.15522264]\n",
      " [0.83394253]\n",
      " [0.9759729 ]\n",
      " [0.14713484]\n",
      " [0.3037626 ]\n",
      " [0.07953263]\n",
      " [0.7670677 ]\n",
      " [0.22532354]\n",
      " [0.98189586]\n",
      " [0.10007229]\n",
      " [0.10505635]\n",
      " [0.36915177]\n",
      " [0.00198505]\n",
      " [0.8914084 ]\n",
      " [0.83394253]\n",
      " [0.10960562]\n",
      " [0.9861576 ]\n",
      " [0.12878853]\n",
      " [0.08201702]\n",
      " [0.54821545]\n",
      " [0.97558814]\n",
      " [0.17110537]\n",
      " [0.33038628]\n",
      " [0.982128  ]\n",
      " [0.20522718]\n",
      " [0.10005537]\n",
      " [0.9760223 ]\n",
      " [0.98790735]\n",
      " [0.35577548]\n",
      " [0.17042008]\n",
      " [0.262994  ]\n",
      " [0.05536836]\n",
      " [0.10505635]\n",
      " [0.16266352]\n",
      " [0.46592796]\n",
      " [0.45794457]\n",
      " [0.13251686]\n",
      " [0.7757483 ]\n",
      " [0.11709882]\n",
      " [0.0782314 ]\n",
      " [0.2592649 ]\n",
      " [0.12083189]\n",
      " [0.41047415]\n",
      " [0.9475107 ]\n",
      " [0.5315919 ]\n",
      " [0.09266683]\n",
      " [0.01848359]\n",
      " [0.97247356]\n",
      " [0.19709547]\n",
      " [0.97207946]\n",
      " [0.12307571]\n",
      " [0.09825944]\n",
      " [0.9716017 ]\n",
      " [0.11651139]\n",
      " [0.98231906]\n",
      " [0.4561063 ]\n",
      " [0.30122897]\n",
      " [0.32645267]\n",
      " [0.28905284]\n",
      " [0.31694236]\n",
      " [0.67606056]\n",
      " [0.73012215]\n",
      " [0.6760792 ]\n",
      " [0.9847698 ]\n",
      " [0.45446807]\n",
      " [0.10025062]\n",
      " [0.97998214]\n",
      " [0.08043581]\n",
      " [0.10025059]\n",
      " [0.09700829]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions.shape)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892,0.0\n",
      "893,0.0\n",
      "894,0.0\n",
      "895,0.0\n",
      "896,0.0\n",
      "897,0.0\n",
      "898,1.0\n",
      "899,0.0\n",
      "900,1.0\n",
      "901,0.0\n",
      "902,0.0\n",
      "903,0.0\n",
      "904,1.0\n",
      "905,0.0\n",
      "906,1.0\n",
      "907,1.0\n",
      "908,0.0\n",
      "909,0.0\n",
      "910,0.0\n",
      "911,1.0\n",
      "912,0.0\n",
      "913,1.0\n",
      "914,1.0\n",
      "915,1.0\n",
      "916,1.0\n",
      "917,0.0\n",
      "918,1.0\n",
      "919,0.0\n",
      "920,0.0\n",
      "921,0.0\n",
      "922,0.0\n",
      "923,0.0\n",
      "924,0.0\n",
      "925,0.0\n",
      "926,0.0\n",
      "927,0.0\n",
      "928,0.0\n",
      "929,1.0\n",
      "930,0.0\n",
      "931,0.0\n",
      "932,0.0\n",
      "933,0.0\n",
      "934,0.0\n",
      "935,1.0\n",
      "936,1.0\n",
      "937,0.0\n",
      "938,0.0\n",
      "939,0.0\n",
      "940,1.0\n",
      "941,0.0\n",
      "942,0.0\n",
      "943,0.0\n",
      "944,1.0\n",
      "945,1.0\n",
      "946,0.0\n",
      "947,0.0\n",
      "948,0.0\n",
      "949,0.0\n",
      "950,0.0\n",
      "951,1.0\n",
      "952,0.0\n",
      "953,0.0\n",
      "954,0.0\n",
      "955,1.0\n",
      "956,0.0\n",
      "957,1.0\n",
      "958,1.0\n",
      "959,0.0\n",
      "960,0.0\n",
      "961,1.0\n",
      "962,1.0\n",
      "963,0.0\n",
      "964,0.0\n",
      "965,0.0\n",
      "966,1.0\n",
      "967,0.0\n",
      "968,0.0\n",
      "969,1.0\n",
      "970,0.0\n",
      "971,1.0\n",
      "972,1.0\n",
      "973,0.0\n",
      "974,0.0\n",
      "975,0.0\n",
      "976,0.0\n",
      "977,0.0\n",
      "978,1.0\n",
      "979,1.0\n",
      "980,1.0\n",
      "981,1.0\n",
      "982,0.0\n",
      "983,0.0\n",
      "984,1.0\n",
      "985,0.0\n",
      "986,0.0\n",
      "987,0.0\n",
      "988,1.0\n",
      "989,0.0\n",
      "990,1.0\n",
      "991,0.0\n",
      "992,1.0\n",
      "993,0.0\n",
      "994,0.0\n",
      "995,0.0\n",
      "996,1.0\n",
      "997,0.0\n",
      "998,0.0\n",
      "999,0.0\n",
      "1000,0.0\n",
      "1001,0.0\n",
      "1002,0.0\n",
      "1003,1.0\n",
      "1004,1.0\n",
      "1005,1.0\n",
      "1006,1.0\n",
      "1007,0.0\n",
      "1008,0.0\n",
      "1009,1.0\n",
      "1010,0.0\n",
      "1011,1.0\n",
      "1012,1.0\n",
      "1013,0.0\n",
      "1014,1.0\n",
      "1015,0.0\n",
      "1016,0.0\n",
      "1017,1.0\n",
      "1018,0.0\n",
      "1019,0.0\n",
      "1020,0.0\n",
      "1021,0.0\n",
      "1022,0.0\n",
      "1023,0.0\n",
      "1024,0.0\n",
      "1025,0.0\n",
      "1026,0.0\n",
      "1027,0.0\n",
      "1028,0.0\n",
      "1029,0.0\n",
      "1030,0.0\n",
      "1031,0.0\n",
      "1032,0.0\n",
      "1033,1.0\n",
      "1034,0.0\n",
      "1035,0.0\n",
      "1036,0.0\n",
      "1037,0.0\n",
      "1038,0.0\n",
      "1039,0.0\n",
      "1040,0.0\n",
      "1041,0.0\n",
      "1042,1.0\n",
      "1043,0.0\n",
      "1044,0.0\n",
      "1045,0.0\n",
      "1046,0.0\n",
      "1047,0.0\n",
      "1048,1.0\n",
      "1049,0.0\n",
      "1050,0.0\n",
      "1051,1.0\n",
      "1052,1.0\n",
      "1053,0.0\n",
      "1054,1.0\n",
      "1055,0.0\n",
      "1056,0.0\n",
      "1057,0.0\n",
      "1058,0.0\n",
      "1059,0.0\n",
      "1060,1.0\n",
      "1061,0.0\n",
      "1062,0.0\n",
      "1063,0.0\n",
      "1064,0.0\n",
      "1065,0.0\n",
      "1066,0.0\n",
      "1067,1.0\n",
      "1068,1.0\n",
      "1069,0.0\n",
      "1070,1.0\n",
      "1071,1.0\n",
      "1072,0.0\n",
      "1073,0.0\n",
      "1074,1.0\n",
      "1075,0.0\n",
      "1076,1.0\n",
      "1077,0.0\n",
      "1078,1.0\n",
      "1079,0.0\n",
      "1080,0.0\n",
      "1081,0.0\n",
      "1082,0.0\n",
      "1083,0.0\n",
      "1084,0.0\n",
      "1085,0.0\n",
      "1086,1.0\n",
      "1087,0.0\n",
      "1088,1.0\n",
      "1089,1.0\n",
      "1090,0.0\n",
      "1091,0.0\n",
      "1092,1.0\n",
      "1093,1.0\n",
      "1094,0.0\n",
      "1095,1.0\n",
      "1096,0.0\n",
      "1097,0.0\n",
      "1098,1.0\n",
      "1099,0.0\n",
      "1100,1.0\n",
      "1101,0.0\n",
      "1102,0.0\n",
      "1103,0.0\n",
      "1104,0.0\n",
      "1105,1.0\n",
      "1106,0.0\n",
      "1107,0.0\n",
      "1108,1.0\n",
      "1109,0.0\n",
      "1110,1.0\n",
      "1111,0.0\n",
      "1112,1.0\n",
      "1113,0.0\n",
      "1114,1.0\n",
      "1115,0.0\n",
      "1116,1.0\n",
      "1117,1.0\n",
      "1118,0.0\n",
      "1119,1.0\n",
      "1120,0.0\n",
      "1121,0.0\n",
      "1122,0.0\n",
      "1123,1.0\n",
      "1124,0.0\n",
      "1125,0.0\n",
      "1126,0.0\n",
      "1127,0.0\n",
      "1128,0.0\n",
      "1129,0.0\n",
      "1130,1.0\n",
      "1131,1.0\n",
      "1132,1.0\n",
      "1133,1.0\n",
      "1134,0.0\n",
      "1135,0.0\n",
      "1136,0.0\n",
      "1137,0.0\n",
      "1138,1.0\n",
      "1139,0.0\n",
      "1140,1.0\n",
      "1141,0.0\n",
      "1142,1.0\n",
      "1143,0.0\n",
      "1144,0.0\n",
      "1145,0.0\n",
      "1146,0.0\n",
      "1147,0.0\n",
      "1148,0.0\n",
      "1149,0.0\n",
      "1150,1.0\n",
      "1151,0.0\n",
      "1152,0.0\n",
      "1153,0.0\n",
      "1154,1.0\n",
      "1155,1.0\n",
      "1156,0.0\n",
      "1157,0.0\n",
      "1158,0.0\n",
      "1159,0.0\n",
      "1160,0.0\n",
      "1161,0.0\n",
      "1162,0.0\n",
      "1163,0.0\n",
      "1164,1.0\n",
      "1165,1.0\n",
      "1166,0.0\n",
      "1167,1.0\n",
      "1168,0.0\n",
      "1169,0.0\n",
      "1170,0.0\n",
      "1171,0.0\n",
      "1172,0.0\n",
      "1173,1.0\n",
      "1174,1.0\n",
      "1175,1.0\n",
      "1176,1.0\n",
      "1177,0.0\n",
      "1178,0.0\n",
      "1179,0.0\n",
      "1180,0.0\n",
      "1181,0.0\n",
      "1182,0.0\n",
      "1183,1.0\n",
      "1184,0.0\n",
      "1185,0.0\n",
      "1186,0.0\n",
      "1187,0.0\n",
      "1188,1.0\n",
      "1189,0.0\n",
      "1190,0.0\n",
      "1191,0.0\n",
      "1192,0.0\n",
      "1193,0.0\n",
      "1194,0.0\n",
      "1195,0.0\n",
      "1196,1.0\n",
      "1197,1.0\n",
      "1198,0.0\n",
      "1199,1.0\n",
      "1200,0.0\n",
      "1201,0.0\n",
      "1202,0.0\n",
      "1203,0.0\n",
      "1204,0.0\n",
      "1205,1.0\n",
      "1206,1.0\n",
      "1207,1.0\n",
      "1208,0.0\n",
      "1209,0.0\n",
      "1210,0.0\n",
      "1211,0.0\n",
      "1212,0.0\n",
      "1213,0.0\n",
      "1214,0.0\n",
      "1215,0.0\n",
      "1216,1.0\n",
      "1217,0.0\n",
      "1218,1.0\n",
      "1219,0.0\n",
      "1220,0.0\n",
      "1221,0.0\n",
      "1222,1.0\n",
      "1223,0.0\n",
      "1224,0.0\n",
      "1225,1.0\n",
      "1226,0.0\n",
      "1227,0.0\n",
      "1228,0.0\n",
      "1229,0.0\n",
      "1230,0.0\n",
      "1231,0.0\n",
      "1232,0.0\n",
      "1233,0.0\n",
      "1234,0.0\n",
      "1235,1.0\n",
      "1236,0.0\n",
      "1237,1.0\n",
      "1238,0.0\n",
      "1239,1.0\n",
      "1240,0.0\n",
      "1241,1.0\n",
      "1242,1.0\n",
      "1243,0.0\n",
      "1244,0.0\n",
      "1245,0.0\n",
      "1246,1.0\n",
      "1247,0.0\n",
      "1248,1.0\n",
      "1249,0.0\n",
      "1250,0.0\n",
      "1251,0.0\n",
      "1252,0.0\n",
      "1253,1.0\n",
      "1254,1.0\n",
      "1255,0.0\n",
      "1256,1.0\n",
      "1257,0.0\n",
      "1258,0.0\n",
      "1259,1.0\n",
      "1260,1.0\n",
      "1261,0.0\n",
      "1262,0.0\n",
      "1263,1.0\n",
      "1264,0.0\n",
      "1265,0.0\n",
      "1266,1.0\n",
      "1267,1.0\n",
      "1268,0.0\n",
      "1269,0.0\n",
      "1270,0.0\n",
      "1271,0.0\n",
      "1272,0.0\n",
      "1273,0.0\n",
      "1274,0.0\n",
      "1275,0.0\n",
      "1276,0.0\n",
      "1277,1.0\n",
      "1278,0.0\n",
      "1279,0.0\n",
      "1280,0.0\n",
      "1281,0.0\n",
      "1282,0.0\n",
      "1283,1.0\n",
      "1284,1.0\n",
      "1285,0.0\n",
      "1286,0.0\n",
      "1287,1.0\n",
      "1288,0.0\n",
      "1289,1.0\n",
      "1290,0.0\n",
      "1291,0.0\n",
      "1292,1.0\n",
      "1293,0.0\n",
      "1294,1.0\n",
      "1295,0.0\n",
      "1296,0.0\n",
      "1297,0.0\n",
      "1298,0.0\n",
      "1299,0.0\n",
      "1300,1.0\n",
      "1301,1.0\n",
      "1302,1.0\n",
      "1303,1.0\n",
      "1304,0.0\n",
      "1305,0.0\n",
      "1306,1.0\n",
      "1307,0.0\n",
      "1308,0.0\n",
      "1309,0.0\n"
     ]
    }
   ],
   "source": [
    "# 输出一份如下的csv文件 名为output.csv\n",
    "# PassengerId,Survived\n",
    "# 892,0\n",
    "# 893,1\n",
    "# 894,0\n",
    "# 895,0\n",
    "# 896,1\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"{test_data.iloc[i]['PassengerId']},{predictions[i][0].round()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为csv文件\n",
    "with open('output.csv', 'w') as f:\n",
    "    f.write(\"PassengerId,Survived\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        # 保留0和1\n",
    "        f.write(f\"{test_data.iloc[i]['PassengerId']},{int(predictions[i][0].round())}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
