{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n",
      "Accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        # 特征索引\n",
    "        self.feature = feature\n",
    "        # 特征阈值\n",
    "        self.threshold = threshold\n",
    "        # 左子树\n",
    "        self.left = left\n",
    "        # 右子树\n",
    "        self.right = right\n",
    "        # 叶节点值\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"训练决策树\"\"\"\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.root = self._grow_tree(X, y)\n",
    "        \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"递归构建决策树\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # 检查停止条件\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           n_samples < self.min_samples_split or \\\n",
    "           n_labels == 1:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # 寻找最佳分割点\n",
    "        feature_idxs = np.arange(n_features)\n",
    "        best_feature, best_threshold = self._best_split(X, y, feature_idxs)\n",
    "        \n",
    "        # 创建子节点\n",
    "        left_idxs = X[:, best_feature] <= best_threshold\n",
    "        right_idxs = X[:, best_feature] > best_threshold\n",
    "        left = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "        \n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "    \n",
    "    def _best_split(self, X, y, feature_idxs):\n",
    "        \"\"\"寻找最佳分割特征和阈值\"\"\"\n",
    "        best_gain = -1\n",
    "        split_feature, split_threshold = None, None\n",
    "        \n",
    "        for feature_idx in feature_idxs:\n",
    "            X_column = X[:, feature_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_feature = feature_idx\n",
    "                    split_threshold = threshold\n",
    "                    \n",
    "        return split_feature, split_threshold\n",
    "    \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        \"\"\"计算信息增益\"\"\"\n",
    "        parent_entropy = self._entropy(y)\n",
    "        \n",
    "        # 生成左右子树\n",
    "        left_idxs = X_column <= threshold\n",
    "        right_idxs = X_column > threshold\n",
    "        \n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # 计算加权平均熵\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(y[left_idxs]), len(y[right_idxs])\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "        \n",
    "        return parent_entropy - child_entropy\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        \"\"\"计算熵\"\"\"\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p > 0])\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        \"\"\"返回最常见的标签\"\"\"\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"预测样本的类别\"\"\"\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"遍历决策树进行预测\"\"\"\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "# 生成示例数据\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 生成分类数据\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=10,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 创建和训练决策树\n",
    "tree = DecisionTree(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "predictions = tree.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[00:39:14] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function logliss\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000147144428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000001473695e8 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\n  [bt] (2) 3   libxgboost.dylib                    0x000000014733d764 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 224\n  [bt] (3) 4   libxgboost.dylib                    0x000000014732f57c xgboost::LearnerConfiguration::Configure() + 1320\n  [bt] (4) 5   libxgboost.dylib                    0x000000014716627c XGBoosterBoostedRounds + 100\n  [bt] (5) 6   libffi.dylib                        0x00000001b20c3050 ffi_call_SYSV + 80\n  [bt] (6) 7   libffi.dylib                        0x00000001b20cbb04 ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x000000010548b9a0 _ctypes_callproc + 1348\n  [bt] (8) 9   _ctypes.cpython-310-darwin.so       0x000000010548430c PyCFuncPtr_call + 1176\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m early_stopping_rounds \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     15\u001b[0m evals\u001b[38;5;241m=\u001b[39m[(dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dtest, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 每10轮打印一次评估结果\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[1;32m     28\u001b[0m pre_label \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m predictions]\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/training.py:176\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    166\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(EarlyStopping(rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds, maximize\u001b[38;5;241m=\u001b[39mmaximize))\n\u001b[1;32m    167\u001b[0m cb_container \u001b[38;5;241m=\u001b[39m CallbackContainer(\n\u001b[1;32m    168\u001b[0m     callbacks,\n\u001b[1;32m    169\u001b[0m     metric\u001b[38;5;241m=\u001b[39mmetric_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcallable\u001b[39m(obj) \u001b[38;5;129;01mor\u001b[39;00m metric_fn \u001b[38;5;129;01mis\u001b[39;00m feval,\n\u001b[1;32m    174\u001b[0m )\n\u001b[0;32m--> 176\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iteration, num_boost_round):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/callback.py:179\u001b[0m, in \u001b[0;36mCallbackContainer.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Function called before training.\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 179\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore_training should return the model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cv:\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/callback.py:374\u001b[0m, in \u001b[0;36mEarlyStopping.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: _Model) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Model:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_round \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_boosted_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/core.py:2743\u001b[0m, in \u001b[0;36mBooster.num_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2741\u001b[0m rounds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2743\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterBoostedRounds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rounds\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/Documents/ai/2022-Machine-Learning-Specializatio/venv/lib/python3.10/site-packages/xgboost/core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [00:39:14] /Users/runner/work/xgboost/xgboost/src/metric/metric.cc:49: Unknown metric function logliss\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000147144428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000001473695e8 xgboost::Metric::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&, xgboost::Context const*) + 124\n  [bt] (2) 3   libxgboost.dylib                    0x000000014733d764 xgboost::LearnerConfiguration::ConfigureMetrics(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 224\n  [bt] (3) 4   libxgboost.dylib                    0x000000014732f57c xgboost::LearnerConfiguration::Configure() + 1320\n  [bt] (4) 5   libxgboost.dylib                    0x000000014716627c XGBoosterBoostedRounds + 100\n  [bt] (5) 6   libffi.dylib                        0x00000001b20c3050 ffi_call_SYSV + 80\n  [bt] (6) 7   libffi.dylib                        0x00000001b20cbb04 ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x000000010548b9a0 _ctypes_callproc + 1348\n  [bt] (8) 9   _ctypes.cpython-310-darwin.so       0x000000010548430c PyCFuncPtr_call + 1176\n\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params ={\n",
    "    'max_depth':5,\n",
    "    'eta':0.3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logliss'\n",
    "}\n",
    "\n",
    "num_rounds =100\n",
    "\n",
    "# 设置早停机制\n",
    "early_stopping_rounds = 10\n",
    "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_rounds,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=10  # 每10轮打印一次评估结果\n",
    ")\n",
    "\n",
    "predictions = model.predict(dtest)\n",
    "\n",
    "pre_label = [1 if p>0.5 else 0 for p in predictions]\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
